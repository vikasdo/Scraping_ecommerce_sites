# Scraping ecommerce websites



Figured an e-commerce aggregator platforms which collects and shows the products information by webcrawling across best 4 major websites using Python libraries and decreased the space complexity of
application by 100% it will automatically recieve the data without any storage
 It contains the main part: First, we have to fetch all the HTML DOM elements in the page and find the feasible parts of dom where the actual content about the products information is placed and combines all the data together from all other sources and displays to the user based on the product searched by user dynamically.
 
 
The following information needs to be extracted from the page:
Product Name
Product price
Product discount
Product image
# Main idea

The advent of internet and smartphones has been good to the e-commerce industry. With millions of customers and billions of dollars at stake, the market has started seeing the many customers.
 Which in turn has led to rise of e-commerce aggregator platforms which collect and show you the information regarding your products from across multiple portals.
For example when planning to buy a smartphone and you would want to see the prices at different platforms at a single place. What does it take to build such an aggregator platform? Hereâ€™s my small take on building an e-commerce site scraper.

# Screenshots

![Image of result_page](https://github.com/vikasdo/Scraping_ecommerce_sites/blob/master/result_page.png)

![Image of search_page](https://github.com/vikasdo/Scraping_ecommerce_sites/blob/master/search_page.png)



# Referrences
https://www.promptcloud.com/blog/customer-spotlight-dandan-price-comparison-startup/
https://towardsdatascience.com/https-medium-com-hiren787-patel-web-scraping-applications-a6f370d316f4
